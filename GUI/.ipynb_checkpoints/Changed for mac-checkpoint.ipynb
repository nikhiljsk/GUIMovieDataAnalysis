{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Enter your choice:\n",
      "1.Image Input\n",
      "2.Text Input\n",
      "3.Exit\n",
      "1\n",
      "Enter the complete path of the image file/Users/nikhiljsk/Desktop/maatr.jpg\n",
      "Hold until we process your Image.....\n"
     ]
    },
    {
     "ename": "TesseractNotFoundError",
     "evalue": "/Users/nikhiljsk/pytesseract/pytesseract.py is not installed or it's not in your path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/nikhiljsk/pytesseract/pytesseract.py': '/Users/nikhiljsk/pytesseract/pytesseract.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b06948708d6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_movie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-b06948708d6a>\u001b[0m in \u001b[0;36mimage_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/deionise.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#extract text from denoised image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0moutput_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     }[output_type]()\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     }[output_type]()\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, return_bytes)\u001b[0m\n\u001b[1;32m    216\u001b[0m         }\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_filename_base'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextsep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m: /Users/nikhiljsk/pytesseract/pytesseract.py is not installed or it's not in your path"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "class ImageProcessing:\n",
    "    \n",
    "    def image_process(self):\n",
    "        \n",
    "        path= os.getcwd()\n",
    "        path += '/raw/'\n",
    "        # load the image \n",
    "        img_path=input(\"Enter the complete path of the image file\")\n",
    "        img=Image.open(img_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        print(\"Hold until we process your Image.....\")\n",
    "        #convert the image type into numpy array for processing\n",
    "        image_data = np.asarray(img)\n",
    "        #denoising the image\n",
    "        dst = cv2.fastNlMeansDenoisingColored(image_data,None,10,10,7,21)\n",
    "        #saving the denoised image\n",
    "        cv2.imwrite(path + '/deionise.png', dst)\n",
    "        #to convert tesseract_cmd file to tesseract.exe\n",
    "        #pytesseract.pytesseract.tesseract_cmd = \"/Users/nikhiljsk/pytesseract/pytesseract.py\"\n",
    "        #pytesseract.pytesseract.tesseract_cmd = \"/Users/nikhiljsk/pytesseract/pytesseract.py\"\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'/anaconda3/lib/python3.6/site-packages'\n",
    "        #converting the image into grayscale\n",
    "        gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)\n",
    "        #saving the grayscale image\n",
    "        cv2.imwrite(path + '/enhancedGrayscaleLineCapture.png', gray)\n",
    "        #to increase the threshold of the image\n",
    "        th1 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                                    cv2.THRESH_BINARY,11,2)\n",
    "        ret2,th2 = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "        ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        blue, green, red = cv2.split(image_data)\n",
    "        blue_edges = cv2.Canny(blue, 100, 10)       \n",
    "        green_edges = cv2.Canny(green, 100, 10)\n",
    "        red_edges = cv2.Canny(red, 100, 10)\n",
    "        edges = blue_edges | green_edges | red_edges\n",
    "        #saving enhanced gray scale threshold,grayscaled images\n",
    "        cv2.imwrite(path + '/enhancedGrayscaleThresholdLineCapture.png', th2)\n",
    "        cv2.imwrite(path + '/bluegreenred.png', edges)\n",
    "        img2=Image.open(path + '/enhancedGrayscaleThresholdLineCapture.png')\n",
    "        img1=Image.open(path + '/bluegreenred.png')\n",
    "        images=Image.open(path + '/deionise.png')\n",
    "        #extract text from denoised image\n",
    "        result=pytesseract.image_to_string(images,lang='eng')\n",
    "        output_temp=result.split()\n",
    "        for i in range(len(output_temp)):\n",
    "            output_temp[i]=output_temp[i].lower()\n",
    "        output_vectors=[]\n",
    "        \"\"\"for i in range(len(output_temp)):\n",
    "            output_vectors.append(len(output_temp[i]))\n",
    "        x=max(output_vectors)\n",
    "        for k in range(len(output_vectors)):\n",
    "            if(x==output_vectors[k]):\n",
    "                x=k\n",
    "                break\n",
    "        output=output_temp[x]\"\"\"\n",
    "        return output_temp    \n",
    "\n",
    "\n",
    "class NLP:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output_vectors=[]\n",
    "        self.input_text_vectors=[]\n",
    "        self.constraints_vectors=[]\n",
    "        self.keywords_vectors=[]\n",
    "        self.output=[]\n",
    "        self.num_words=1000\n",
    "        self.number_of_constraints=0\n",
    "        ck = pd.read_csv(\"./const_key.csv\")  #ck.iloc[:, 0]\n",
    "        self.keywords=ck.iloc[0:3, 1].tolist()\n",
    "        self.constraints = (ck.iloc[:, 0]).tolist()\n",
    "        self.input_text = \"\"\n",
    "        self.temp =[]\n",
    "        self.key_count = 0\n",
    "        \n",
    "    def input_query(self):\n",
    "        self.input_text=input(\"Enter Your Query:\\n\")\n",
    "        \n",
    "    def processing(self):\n",
    "        self.temp=(self.input_text).split(\" \")\n",
    "        l1=self.temp+self.constraints+self.keywords\n",
    "        l = [l1]\n",
    "        tokenizer=Tokenizer(num_words=self.num_words)\n",
    "        tokenizer.fit_on_texts(l)\n",
    "        token_outputs=tokenizer.word_index\n",
    "        for i in range(len(self.temp)):\n",
    "            self.input_text_vectors.append(token_outputs[self.temp[i]])\n",
    "        for j in range(len(self.constraints)):\n",
    "            self.constraints_vectors.append(token_outputs[self.constraints[j]])\n",
    "        for k in range(len(self.keywords)):\n",
    "            self.keywords_vectors.append(token_outputs[self.keywords[k]])\n",
    "        for m in range(len(self.input_text_vectors)):\n",
    "            for n in range(len(self.constraints_vectors)):\n",
    "                if(self.input_text_vectors[m]==self.constraints_vectors[n]):\n",
    "                    self.output_vectors.append(self.input_text_vectors[m])\n",
    "                    self.number_of_constraints+=1\n",
    "        for o in range(len(self.input_text_vectors)):\n",
    "            for p in range(len(self.keywords_vectors)):\n",
    "                if(self.input_text_vectors[o]==self.keywords_vectors[p]):#must handle array index out of bound error and print query incomplete\n",
    "                    try:\n",
    "                        self.key_count += 1\n",
    "                        self.output_vectors.append(self.input_text_vectors[o+1])\n",
    "                    except IndexError as e:\n",
    "                        print(\"Query does not contain enough parameters.\")\n",
    "                        return self.processing()\n",
    "        self.output.append(self.number_of_constraints)\n",
    "        for q in range(len(self.output_vectors)):\n",
    "            for value,vectors in token_outputs.items():\n",
    "                if (self.output_vectors[q]==vectors):\n",
    "                    self.output.append(value)\n",
    "        if 'predict' in self.output:\n",
    "            return self.output\n",
    "        if self.number_of_constraints <= self.key_count:\n",
    "            return self.output\n",
    "        else:\n",
    "            print(\"Not enough keywords\")\n",
    "            self.input_query()\n",
    "\n",
    "class Visualize:\n",
    "    def __init__(self):\n",
    "        self.df1 = pd.read_csv('./movie_name_char_mentions_centrality.csv')\n",
    "        self.df2 = pd.read_csv('./movie_emotion_year.csv')\n",
    "        self.df3 = pd.read_csv('./movie_singer_count.csv')\n",
    "        self.df4 = pd.read_csv('./movie_plot.csv')\n",
    "        self.df5 = pd.read_csv('./movie_all.csv')\n",
    "        \n",
    "    def lead_role(self, q):\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", q, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        result = 'actor' in ser.values\n",
    "        if(result):\n",
    "            print(\"The lead role is 'actor'\")\n",
    "            print(\"The type of role played is: \", col[col['name'].values=='actor']['character'])\n",
    "            \n",
    "        else:\n",
    "            col = col.sort_values(by=['count'], ascending=False)\n",
    "            ser = col['name']\n",
    "            nam = ser.values[0]\n",
    "            ind = ser[ser==nam].index[0]\n",
    "            print(\"The lead role is:\", nam)\n",
    "            print(\"The type of role played is: \", self.df1[self.df1['index']==ind]['character'].values[0])\n",
    "            \n",
    "    def characters(self, q):\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", q, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        print(\"The characters in the movies\", q, \"include:\")\n",
    "        print(col[['name', 'character']])\n",
    "        \n",
    "    def character(self, q, m):\n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        nam = \"NULL\"\n",
    "        try:\n",
    "            nam = ser[ser==q].values[0]\n",
    "        except IndexError as e:\n",
    "            print(\"The character \", q, \" is not found in the database.Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        print(\"The role is:\", nam)\n",
    "        print(\"The type of role played is: \", self.df1[self.df1['index']==ind]['character'].values[0])\n",
    "        \n",
    "    def plot(self, m):\n",
    "        pd.set_option('display.max_colwidth', -1)\n",
    "        col = self.df4[self.df4['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        print(\"The plot of the film goes like: \")\n",
    "        print(col['plot'])\n",
    "        \n",
    "    def appearances(self, c, m):\n",
    "        col = self.df1[self.df1['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        try:\n",
    "            nam = ser[ser==c].values[0]\n",
    "        except IndexError as e:\n",
    "            print(\"The character \", c, \" is not found in the database.Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        print(\"The role is:\", nam)\n",
    "        print(\"The number of appearances are: \", self.df1[self.df1['index']==ind]['count'].values[0])\n",
    "        print(\"The average centrality is: \", self.df1[self.df1['index']==ind]['average centrality'].values[0])\n",
    "        print(\"The total centrality is: \", self.df1[self.df1['index']==ind]['total centrality'].values[0])\n",
    "       \n",
    "        \n",
    "    def year(self, m):\n",
    "        col = self.df2[self.df2['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        print(\"The movie\", m, \"released in the year\",col['year'].values[0])\n",
    "        \n",
    "    def songs(self, m):\n",
    "        col = self.df3[self.df3['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        singers = col['singer_name'].values.tolist()\n",
    "        print(\"The movie\", m, \"has\", col['song_count'].sum(), \"songs.\\n\")\n",
    "        print(\"And the singers are:\\n\", \"\\n \".join(singers))\n",
    "        \n",
    "    def average_emotion(self, m, n):\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        se = col['emotion'].value_counts()\n",
    "        if(n==0):\n",
    "            fig, ax = plt.subplots(figsize=(12, 6), subplot_kw=dict(aspect=\"equal\"))\n",
    "            recipe = se.index\n",
    "            data = se.values\n",
    "            wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-40)\n",
    "            bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "            kw = dict(xycoords='data', textcoords='data', arrowprops=dict(arrowstyle=\"-\"),\n",
    "                      bbox=bbox_props, zorder=0, va=\"center\")\n",
    "            for i, p in enumerate(wedges):\n",
    "                ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "                y = np.sin(np.deg2rad(ang))\n",
    "                x = np.cos(np.deg2rad(ang))\n",
    "                horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "                connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
    "                kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "                ax.annotate(recipe[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),horizontalalignment=horizontalalignment, **kw)\n",
    "            ax.set_title(\"Average Emotion\")\n",
    "        \n",
    "            plt.show()\n",
    "        \n",
    "        maxi = max(se.values)\n",
    "        mini = min(se.values)\n",
    "        max_per = (maxi/sum(se.values))*100\n",
    "        min_per = (mini/sum(se.values))*100\n",
    "        if(n==2):\n",
    "            print('\\nThe most expressed emotion in the film is \"',se[se == maxi].index[0],'\"',\" and constitutes to \", max_per,\"%\",sep=\"\")\n",
    "        if(n==1):\n",
    "            print('\\nThe least expressed emotion in the film is \"',se[se == mini].index[0],'\"',\" and constitutes to \", min_per,\"%\", sep=\"\")\n",
    "       \n",
    "        # creating word cloud\n",
    "        if(n==0):\n",
    "            self.create_wordcloud(col)\n",
    "        \n",
    "        if(n==0):\n",
    "            # genre of the film\n",
    "            self.genre(m)\n",
    "        \n",
    "    def create_wordcloud(self, q):\n",
    "        from wordcloud import WordCloud, STOPWORDS \n",
    "        print(\"\\n\\nThe wordcloud created for the emotions of the data in the film:\\n\")\n",
    "        comment_words = ' '\n",
    "        stopwords = set(STOPWORDS) \n",
    "\n",
    "        for val in q: \n",
    "            val = str(val) \n",
    "            tokens = val.split()  \n",
    "            for i in range(len(tokens)): \n",
    "                tokens[i] = tokens[i].lower() \n",
    "\n",
    "            for words in tokens: \n",
    "                comment_words = comment_words + words + ' '\n",
    "\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800, \n",
    "                        background_color ='white', \n",
    "                        stopwords = stopwords, \n",
    "                        min_font_size = 10).generate(' '.join(q['emotion'])) \n",
    "\n",
    "        plt.figure(figsize = (4, 4), facecolor = None) \n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout(pad = 0) \n",
    "        plt.show()\n",
    "        print(\"Note: The the size of the word increases with higher expressed emotion.\")\n",
    "        \n",
    "    def genre(self, m):\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        se = col['emotion'].value_counts()\n",
    "        gen = se[se == max(se.values)].index[0]\n",
    "        \n",
    "        #fuzzying the output\n",
    "        \n",
    "        if(gen==\"happy\"):\n",
    "            genre = \"Family-Entertainer\"\n",
    "        elif(gen == \"neutral\"):\n",
    "            genre = \"Drama\"\n",
    "        elif(gen == \"sad\"):\n",
    "            genre = \"Melo-Drama\"\n",
    "        elif(gen == \"angry\"):\n",
    "            genre = \"Action\"\n",
    "        elif(gen == \"fear\"):\n",
    "            genre = \"Horror\"\n",
    "        elif(gen==\"suprise\"):\n",
    "            genre = \"Suspence Thriller\"\n",
    "        elif(gen==\"disgust\"):\n",
    "            genre = \"Crime-Thriller\"\n",
    "        print(\"GENRE:\")\n",
    "        print(\"The movie \", m, \" is a \", genre, \" genre film.\", sep=\"\")\n",
    "        \n",
    "    def length_of_movie(self, m):\n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        se1 = col['mentions'].sum()\n",
    "        se2 = col['count'].sum()\n",
    "        se3 = col['total centrality'].sum()\n",
    "        se4 = col['average centrality'].sum()\n",
    "        result = se1 + (se3/se2) + se4                               # creating an estimation variable\n",
    "        est_time = 150\n",
    "        est_result = 70\n",
    "        if(35<result<est_result):                                    # fuzzyfying the result into time or length of movie\n",
    "            length = est_time\n",
    "        elif(30<result<est_result/2):\n",
    "            length = est_time-20\n",
    "        elif(70<result<est_result*2):\n",
    "            length = est_time+20\n",
    "        elif(140<result<est_result*4):\n",
    "            length = est_time+10\n",
    "        else:\n",
    "            length = est_time - 10\n",
    "        print(\"The predicted length of movie \", m, \" on the basis of Centrality and Mentions is about \", np.round((length/60), 2),sep=\"\")\n",
    "\n",
    "    def trends(self, bol):\n",
    "        df = {}\n",
    "        for i in range(10):\n",
    "            df[i] = self.df2[self.df2['year']==2008+i]['emotion'].value_counts().to_frame()\n",
    "            df[i].columns = [2008+i]\n",
    "        df_area = pd.concat([df[0], df[1], df[2], df[3], df[4], df[5], df[6], df[7],df[8], df[9]], axis=1)\n",
    "        if(bol):\n",
    "            print(df_area)\n",
    "            df_area.transpose().plot.area()\n",
    "            plt.xlabel(\"Year\")\n",
    "            plt.ylabel(\"Range\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            return df_area\n",
    "        \n",
    "    def predict(self):\n",
    "        df_area = self.trends(False)\n",
    "        print(df_area)\n",
    "        # Data-Preprocessing\n",
    "        z = pd.read_csv('./trend_emotion.csv')\n",
    "        X = z.iloc[:, :-1]\n",
    "        y = z.iloc[:, -1]\n",
    "        # Spliting Data \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        # Linear Regression\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, y_train)\n",
    "        predictions_lin = lm.predict(X_test)\n",
    "       \n",
    "        # Calculating the Result in terms of errors\n",
    "        from sklearn import metrics\n",
    "        result = list()\n",
    "        result.append(metrics.mean_squared_error(y_test, predictions_lin))\n",
    "        result = np.array(result)\n",
    "        new = list()\n",
    "        emotions = ['angry', 'disgust', 'fear', 'happy', 'neurtal', 'sad', 'suprise']\n",
    "        print(\"\\n\")\n",
    "        for i in range(7):\n",
    "            print(\"Enter value of\",emotions[i],\":\", end=\"\")\n",
    "            new.append(int(input()))\n",
    "        result = lm.predict([new])\n",
    "        print(\"\\nThe predicted year according the values given is \",result[0])\n",
    "        \n",
    "    def image_movie(self, arr):\n",
    "        for i in range(len(arr)):\n",
    "            print(arr[i])\n",
    "            if arr[i] in self.df5.iloc[:, -1].values:\n",
    "                m = arr[i]\n",
    "                self.lead_role(m)\n",
    "                self.characters(m)\n",
    "                self.plot(m)\n",
    "                self.year(m)\n",
    "                self.songs(m)\n",
    "                self.average_emotion(m, 0)\n",
    "                self.length_of_movie(m)\n",
    "                return\n",
    "        print(\"Could not find the movie in the dataset\")\n",
    "        \n",
    "\n",
    "# Driver Code\n",
    "\n",
    "# input using NLP\n",
    "ext = 0         # checking for exit condition  \n",
    "while ext!=1:\n",
    "    obj = Visualize()\n",
    "    print(\"\\n\")\n",
    "    choice = int(input(\"Enter your choice:\\n1.Image Input\\n2.Text Input\\n3.Exit\\n\"))\n",
    "    if choice == 1:\n",
    "        ob = ImageProcessing()\n",
    "        tensor = ob.image_process()\n",
    "        obj.image_movie(tensor)\n",
    "        continue\n",
    "    elif choice == 2:\n",
    "        print(\"Queries can be framed using the following to get optimum results:\")\n",
    "        print(\"1.characters\\n2.plot\\n3.genre\\n4.attitude\\n5.appearances\\n6.year\\n7.songs\\n8.length\\n9.variation\\n10.predict\\n11.emotion\\n12.role\\n13.exit\\n14.movie\\n15.emotions\\n16.character\\n\")\n",
    "        ob = NLP()\n",
    "        ob.input_query()\n",
    "        tensor = ob.processing()\n",
    "    elif choice == 3:\n",
    "        print(\"Interupt Process\")\n",
    "        break;\n",
    "    else:\n",
    "        print(\"Invalid Input\")\n",
    "        continue\n",
    "    # Visualizing the queries\n",
    "    \n",
    "    count = tensor[0]\n",
    "    for i in range(1, tensor[0]+1):\n",
    "        \n",
    "        if tensor[i]==\"role\":\n",
    "            obj.lead_role(tensor[i + count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"characters\":\n",
    "            obj.characters(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"attitude\":\n",
    "            obj.character(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"plot\":\n",
    "            obj.plot(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"appearances\":\n",
    "            obj.appearances(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"year\":\n",
    "            obj.year(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"songs\":\n",
    "            obj.songs(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"emotion\":\n",
    "            try:\n",
    "                if (\"average\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 0)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"minor\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 1)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"major\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 2)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif(\"predict\" in ob.temp):\n",
    "                    obj.predict()\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "            except IndexError as e:\n",
    "                print(\"Not enough parameters\")\n",
    "                break\n",
    "        \n",
    "        elif tensor[i]==\"genre\":\n",
    "            obj.genre(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"length\":\n",
    "            obj.length_of_movie(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif tensor[i]==\"variation\":\n",
    "            obj.trends(True)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "        elif tensor[i]==\"exit\":\n",
    "            print(\"Process Interupt\")\n",
    "            ext = 1\n",
    "        else:\n",
    "            print(\"Query does not contain enough parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def process_input_text_query(input_string):\n",
    "    ob = NLP()\n",
    "    ob.input_query(input_string)\n",
    "    tensor = ob.processing()\n",
    "    output_list = generic_process(tensor, ob)\n",
    "    return output_string\n",
    "\n",
    "def process_input_image_query(path):\n",
    "    ob = ImageProcessing()\n",
    "    tensor = ob.image_process()\n",
    "    output_list = obj.image_movie(tensor)          # Contains string, image saved path\n",
    "    return output_list\n",
    "    \n",
    "def generic_process(tensor, obj):\n",
    "    count = tensor[0]\n",
    "    for i in range(1, tensor[0]+1):\n",
    "        \n",
    "        if tensor[i]==\"role\":\n",
    "            obj.lead_role(tensor[i + count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"characters\":\n",
    "            obj.characters(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"attitude\":\n",
    "            obj.character(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"plot\":\n",
    "            obj.plot(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"appearances\":\n",
    "            obj.appearances(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"year\":\n",
    "            obj.year(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"songs\":\n",
    "            obj.songs(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"emotion\":\n",
    "            try:\n",
    "                if (\"average\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 0)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"minor\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 1)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"major\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 2)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif(\"predict\" in ob.temp):\n",
    "                    obj.predict()\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "            except IndexError as e:\n",
    "                print(\"Not enough parameters\")\n",
    "                break\n",
    "        \n",
    "        elif tensor[i]==\"genre\":\n",
    "            obj.genre(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"length\":\n",
    "            obj.length_of_movie(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif tensor[i]==\"variation\":\n",
    "            obj.trends(True)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"Query does not contain enough parameters.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nikhiljsk/Desktop/movie_data_analysis-master/Movie_analysis/Movie Analysis'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
