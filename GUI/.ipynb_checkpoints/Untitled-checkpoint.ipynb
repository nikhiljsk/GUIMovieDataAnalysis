{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Enter your choice:\n",
      "1.Image Input\n",
      "2.Text Input\n",
      "3.Exit\n",
      "3\n",
      "Interupt Process\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "\n",
    "\n",
    "class NLP:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output_vectors=[]\n",
    "        self.input_text_vectors=[]\n",
    "        self.constraints_vectors=[]\n",
    "        self.keywords_vectors=[]\n",
    "        self.output=[]\n",
    "        self.num_words=1000\n",
    "        self.number_of_constraints=0\n",
    "        ck = pd.read_csv(\"./const_key.csv\")  #ck.iloc[:, 0]\n",
    "        self.keywords=ck.iloc[0:3, 1].tolist()\n",
    "        self.constraints = (ck.iloc[:, 0]).tolist()\n",
    "        self.input_text = \"\"\n",
    "        self.temp =[]\n",
    "        self.key_count = 0\n",
    "        \n",
    "    def input_query(self, input_string):\n",
    "        self.input_text=input_string\n",
    "        \n",
    "    def processing(self):\n",
    "        self.temp=(self.input_text).split(\" \")\n",
    "        l1=self.temp+self.constraints+self.keywords\n",
    "        l = [l1]\n",
    "        tokenizer=Tokenizer(num_words=self.num_words)\n",
    "        tokenizer.fit_on_texts(l)\n",
    "        token_outputs=tokenizer.word_index\n",
    "        for i in range(len(self.temp)):\n",
    "            self.input_text_vectors.append(token_outputs[self.temp[i]])\n",
    "        for j in range(len(self.constraints)):\n",
    "            self.constraints_vectors.append(token_outputs[self.constraints[j]])\n",
    "        for k in range(len(self.keywords)):\n",
    "            self.keywords_vectors.append(token_outputs[self.keywords[k]])\n",
    "        for m in range(len(self.input_text_vectors)):\n",
    "            for n in range(len(self.constraints_vectors)):\n",
    "                if(self.input_text_vectors[m]==self.constraints_vectors[n]):\n",
    "                    self.output_vectors.append(self.input_text_vectors[m])\n",
    "                    self.number_of_constraints+=1\n",
    "        for o in range(len(self.input_text_vectors)):\n",
    "            for p in range(len(self.keywords_vectors)):\n",
    "                if(self.input_text_vectors[o]==self.keywords_vectors[p]):#must handle array index out of bound error and print query incomplete\n",
    "                    try:\n",
    "                        self.key_count += 1\n",
    "                        self.output_vectors.append(self.input_text_vectors[o+1])\n",
    "                    except IndexError as e:\n",
    "                        print(\"Query does not contain enough parameters.\")\n",
    "                        return self.processing()\n",
    "        self.output.append(self.number_of_constraints)\n",
    "        for q in range(len(self.output_vectors)):\n",
    "            for value,vectors in token_outputs.items():\n",
    "                if (self.output_vectors[q]==vectors):\n",
    "                    self.output.append(value)\n",
    "        if 'predict' in self.output:\n",
    "            return self.output\n",
    "        if self.number_of_constraints <= self.key_count:\n",
    "            return self.output\n",
    "        else:\n",
    "            print(\"Not enough keywords\")\n",
    "            self.input_query()\n",
    "\n",
    "class Visualize:\n",
    "    def __init__(self):\n",
    "        self.df1 = pd.read_csv('./movie_name_char_mentions_centrality.csv')\n",
    "        self.df2 = pd.read_csv('./movie_emotion_year.csv')\n",
    "        self.df3 = pd.read_csv('./movie_singer_count.csv')\n",
    "        self.df4 = pd.read_csv('./movie_plot.csv')\n",
    "        self.df5 = pd.read_csv('./movie_all.csv')\n",
    "        \n",
    "    def lead_role(self, q):\n",
    "        output_string = \"\"\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            output_string += str(\"The movie \"+  str(q) + \" is not found in the database. Try again with another value.\")\n",
    "            return output_string\n",
    "        ser = col['name']\n",
    "        result = 'actor' in ser.values\n",
    "        if(result):\n",
    "            output_string += \"The lead role is 'actor'\" + str(\"\\nThe type of role played is: \" + str(col[col['name'].values=='actor']['character']))\n",
    "            return output_string\n",
    "        else:\n",
    "            col = col.sort_values(by=['count'], ascending=False)\n",
    "            ser = col['name']\n",
    "            nam = ser.values[0]\n",
    "            ind = ser[ser==nam].index[0]\n",
    "            output_string += str(\"The lead role is:\" + str(nam))\n",
    "            output_string += str(\"\\nThe type of role played is: \" +  str(self.df1[self.df1['index']==ind]['character'].values[0]))\n",
    "            return output_string\n",
    "            \n",
    "    def characters(self, q):\n",
    "        output_string = \"\"\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(q) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        ser = col['name']\n",
    "        output_string += \"The characters in the movies \" + str(q) + \" include:\\n\" + str(col[['name', 'character']])\n",
    "        return output_string\n",
    "        \n",
    "    def character(self, q, m):\n",
    "        output_string = \"\"\n",
    "        \n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(m) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        ser = col['name']\n",
    "        nam = \"NULL\"\n",
    "        try:\n",
    "            nam = ser[ser==q].values[0]\n",
    "        except IndexError as e:\n",
    "            output_string += \"The character \" + str(q) + \" is not found in the database.Try again with another value.\"\n",
    "            return output_string\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        output_string += \"The role is: \" + str(nam) + \"\\nThe type of role played is: \" + str(self.df1[self.df1['index']==ind]['character'].values[0])\n",
    "        return output_string\n",
    "        \n",
    "    def plot(self, m):\n",
    "        output_string = \"\"\n",
    "        pd.set_option('display.max_colwidth', -1)\n",
    "        col = self.df4[self.df4['movie']==m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(m) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        output_string += \"The plot of the film goes like: \" + str(col['plot'])\n",
    "        return output_string\n",
    "        \n",
    "    def appearances(self, c, m):\n",
    "        output_string = \"\"\n",
    "        col = self.df1[self.df1['movie'] == m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(m) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        ser = col['name']\n",
    "        try:\n",
    "            nam = ser[ser==c].values[0]\n",
    "        except IndexError as e:\n",
    "            output_string += \"The character \" + str(c) + \" is not found in the database.Try again with another value.\"\n",
    "            return output_string\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        output_string += \"The role is:\" + str(nam)\n",
    "        output_string += \"\\nThe number of appearances are: \" + str(self.df1[self.df1['index']==ind]['count'].values[0])\n",
    "        output_string += \"\\nThe average centrality is: \" + str(self.df1[self.df1['index']==ind]['average centrality'].values[0])\n",
    "        output_string += \"\\nThe total centrality is: \" +  str(self.df1[self.df1['index']==ind]['total centrality'].values[0])\n",
    "        return output_string\n",
    "       \n",
    "        \n",
    "    def year(self, m):\n",
    "        output_string = \"\"\n",
    "        col = self.df2[self.df2['movie'] == m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(m) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        output_string += \"The movie \" + str(m) + \" released in the year \" + str(col['year'].values[0])\n",
    "        return output_string\n",
    "        \n",
    "    def songs(self, m):\n",
    "        output_string = \"\"\n",
    "        col = self.df3[self.df3['movie'] == m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(m) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        singers = col['singer_name'].values.tolist()\n",
    "        output_string += \"The movie \" + str(m) + \" has \" + str(col['song_count'].sum(), \" songs.\\n\")\n",
    "        output_string += \"And the singers are:\\n\" + str(singers)\n",
    "        return output_string\n",
    "        \n",
    "    def average_emotion(self, m, n):\n",
    "        output_string = \"\"\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(m) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        se = col['emotion'].value_counts()\n",
    "        if(n==0):\n",
    "            fig, ax = plt.subplots(figsize=(12, 6), subplot_kw=dict(aspect=\"equal\"))\n",
    "            recipe = se.index\n",
    "            data = se.values\n",
    "            wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-40)\n",
    "            bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "            kw = dict(xycoords='data', textcoords='data', arrowprops=dict(arrowstyle=\"-\"),\n",
    "                      bbox=bbox_props, zorder=0, va=\"center\")\n",
    "            for i, p in enumerate(wedges):\n",
    "                ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "                y = np.sin(np.deg2rad(ang))\n",
    "                x = np.cos(np.deg2rad(ang))\n",
    "                horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "                connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
    "                kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "                ax.annotate(recipe[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),horizontalalignment=horizontalalignment, **kw)\n",
    "            ax.set_title(\"Average Emotion\")\n",
    "        \n",
    "            plt.show()\n",
    "        \n",
    "        maxi = max(se.values)\n",
    "        mini = min(se.values)\n",
    "        max_per = (maxi/sum(se.values))*100\n",
    "        min_per = (mini/sum(se.values))*100\n",
    "        if(n==2):\n",
    "            output_string += '\\nThe most expressed emotion in the film is ' + str(se[se == maxi].index[0]) + \" and constitutes to \" + str(max_per) + \"%\"\n",
    "        if(n==1):\n",
    "            output_string += '\\nThe most expressed emotion in the film is ' + str(se[se == mini].index[0]) + \" and constitutes to \" + str(min_per) + \"%\"\n",
    "       \n",
    "        # creating word cloud\n",
    "        if(n==0):\n",
    "            self.create_wordcloud(col)\n",
    "        \n",
    "        if(n==0):\n",
    "            # genre of the film\n",
    "            output_string += self.genre(m, output_string)\n",
    "            \n",
    "        return output_string\n",
    "        \n",
    "    def create_wordcloud(self, q):\n",
    "        from wordcloud import WordCloud, STOPWORDS \n",
    "        #print(\"\\n\\nThe wordcloud created for the emotions of the data in the film:\\n\")\n",
    "        comment_words = ' '\n",
    "        stopwords = set(STOPWORDS) \n",
    "\n",
    "        for val in q: \n",
    "            val = str(val) \n",
    "            tokens = val.split()  \n",
    "            for i in range(len(tokens)): \n",
    "                tokens[i] = tokens[i].lower() \n",
    "\n",
    "            for words in tokens: \n",
    "                comment_words = comment_words + words + ' '\n",
    "\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800, \n",
    "                        background_color ='white', \n",
    "                        stopwords = stopwords, \n",
    "                        min_font_size = 10).generate(' '.join(q['emotion'])) \n",
    "\n",
    "        plt.figure(figsize = (4, 4), facecolor = None) \n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout(pad = 0) \n",
    "        plt.show()\n",
    "        #print(\"Note: The the size of the word increases with higher expressed emotion.\")\n",
    "        \n",
    "    def genre(self, m, output_string=None):\n",
    "        if output_string == None:\n",
    "            output_string = \"\"\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + m + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        se = col['emotion'].value_counts()\n",
    "        gen = se[se == max(se.values)].index[0]\n",
    "        \n",
    "        #fuzzying the output\n",
    "        \n",
    "        if(gen==\"happy\"):\n",
    "            genre = \"Family-Entertainer\"\n",
    "        elif(gen == \"neutral\"):\n",
    "            genre = \"Drama\"\n",
    "        elif(gen == \"sad\"):\n",
    "            genre = \"Melo-Drama\"\n",
    "        elif(gen == \"angry\"):\n",
    "            genre = \"Action\"\n",
    "        elif(gen == \"fear\"):\n",
    "            genre = \"Horror\"\n",
    "        elif(gen==\"suprise\"):\n",
    "            genre = \"Suspence Thriller\"\n",
    "        elif(gen==\"disgust\"):\n",
    "            genre = \"Crime-Thriller\"\n",
    "        output_string += \"\\nGENRE:\\n\"\n",
    "        output_string += \"The movie \" + str(m) + \" is a \" + str(genre) + \" genre film.\"\n",
    "        return output_string\n",
    "        \n",
    "    def length_of_movie(self, m):\n",
    "        output_string = \"\"\n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            output_string += \"The movie \" + str(m) + \" is not found in the database. Try again with another value.\"\n",
    "            return output_string\n",
    "        se1 = col['mentions'].sum()\n",
    "        se2 = col['count'].sum()\n",
    "        se3 = col['total centrality'].sum()\n",
    "        se4 = col['average centrality'].sum()\n",
    "        result = se1 + (se3/se2) + se4                               # creating an estimation variable\n",
    "        est_time = 150\n",
    "        est_result = 70\n",
    "        if(35<result<est_result):                                    # fuzzyfying the result into time or length of movie\n",
    "            length = est_time\n",
    "        elif(30<result<est_result/2):\n",
    "            length = est_time-20\n",
    "        elif(70<result<est_result*2):\n",
    "            length = est_time+20\n",
    "        elif(140<result<est_result*4):\n",
    "            length = est_time+10\n",
    "        else:\n",
    "            length = est_time - 10\n",
    "        output_string += \"The predicted length of movie \" + m + \" on the basis of Centrality and Mentions is about \" + str(np.round((length/60), 2))\n",
    "        return output_string\n",
    "\n",
    "    def trends(self, bol):\n",
    "        output_string = \"\"\n",
    "        df = {}\n",
    "        for i in range(10):\n",
    "            df[i] = self.df2[self.df2['year']==2008+i]['emotion'].value_counts().to_frame()\n",
    "            df[i].columns = [2008+i]\n",
    "        df_area = pd.concat([df[0], df[1], df[2], df[3], df[4], df[5], df[6], df[7],df[8], df[9]], axis=1)\n",
    "        if(bol):\n",
    "            print(df_area)\n",
    "            df_area.transpose().plot.area()\n",
    "            plt.xlabel(\"Year\")\n",
    "            plt.ylabel(\"Range\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            return df_area\n",
    "        \n",
    "    def predict(self):\n",
    "        df_area = self.trends(False)\n",
    "        # ?? print(df_area)\n",
    "        # Data-Preprocessing\n",
    "        z = pd.read_csv('./trend_emotion.csv')\n",
    "        X = z.iloc[:, :-1]\n",
    "        y = z.iloc[:, -1]\n",
    "        # Spliting Data \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        # Linear Regression\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, y_train)\n",
    "        predictions_lin = lm.predict(X_test)\n",
    "       \n",
    "        # Calculating the Result in terms of errors\n",
    "        from sklearn import metrics\n",
    "        result = list()\n",
    "        result.append(metrics.mean_squared_error(y_test, predictions_lin))\n",
    "        result = np.array(result)\n",
    "        new = list()\n",
    "        emotions = ['angry', 'disgust', 'fear', 'happy', 'neurtal', 'sad', 'suprise']\n",
    "        print(\"\\n\")\n",
    "        for i in range(7):\n",
    "            print(\"Enter value of\",emotions[i],\":\", end=\"\")\n",
    "            new.append(int(input()))\n",
    "        result = lm.predict([new])\n",
    "        print(\"\\nThe predicted year according the values given is \",result[0])\n",
    "        \n",
    "    def image_movie(self, arr):\n",
    "        for i in range(len(arr)):\n",
    "            print(arr[i])\n",
    "            if arr[i] in self.df5.iloc[:, -1].values:\n",
    "                m = arr[i]\n",
    "                self.lead_role(m)\n",
    "                self.characters(m)\n",
    "                self.plot(m)\n",
    "                self.year(m)\n",
    "                self.songs(m)\n",
    "                self.average_emotion(m, 0)\n",
    "                self.length_of_movie(m)\n",
    "                return\n",
    "        print(\"Could not find the movie in the dataset\")\n",
    "        \n",
    "\n",
    "# Driver Code\n",
    "\n",
    "# input using NLP\n",
    "ext = 0         # checking for exit condition  \n",
    "while ext!=1:\n",
    "    obj = Visualize()\n",
    "    print(\"\\n\")\n",
    "    choice = int(input(\"Enter your choice:\\n1.Image Input\\n2.Text Input\\n3.Exit\\n\"))\n",
    "    if choice == 1:\n",
    "        ob = ImageProcessing()\n",
    "        tensor = ob.image_process()\n",
    "        obj.image_movie(tensor)\n",
    "        continue\n",
    "    elif choice == 2:\n",
    "        print(\"Queries can be framed using the following to get optimum results:\")\n",
    "        print(\"1.characters\\n2.plot\\n3.genre\\n4.attitude\\n5.appearances\\n6.year\\n7.songs\\n8.length\\n9.variation\\n10.predict\\n11.emotion\\n12.role\\n13.exit\\n14.movie\\n15.emotions\\n16.character\\n\")\n",
    "        ob = NLP()\n",
    "        ob.input_query()\n",
    "        tensor = ob.processing()\n",
    "    elif choice == 3:\n",
    "        print(\"Interupt Process\")\n",
    "        break;\n",
    "    else:\n",
    "        print(\"Invalid Input\")\n",
    "        continue\n",
    "    # Visualizing the queries\n",
    "    \n",
    "    count = tensor[0]\n",
    "    for i in range(1, tensor[0]+1):\n",
    "        \n",
    "        if tensor[i]==\"role\":\n",
    "            obj.lead_role(tensor[i + count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"characters\":\n",
    "            obj.characters(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"attitude\":\n",
    "            obj.character(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"plot\":\n",
    "            obj.plot(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"appearances\":\n",
    "            obj.appearances(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"year\":\n",
    "            obj.year(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"songs\":\n",
    "            obj.songs(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"emotion\":\n",
    "            try:\n",
    "                if (\"average\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 0)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"minor\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 1)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"major\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 2)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif(\"predict\" in ob.temp):\n",
    "                    obj.predict()\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "            except IndexError as e:\n",
    "                print(\"Not enough parameters\")\n",
    "                break\n",
    "        \n",
    "        elif tensor[i]==\"genre\":\n",
    "            obj.genre(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"length\":\n",
    "            obj.length_of_movie(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif tensor[i]==\"variation\":\n",
    "            obj.trends(True)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "        elif tensor[i]==\"exit\":\n",
    "            print(\"Process Interupt\")\n",
    "            ext = 1\n",
    "        else:\n",
    "            print(\"Query does not contain enough parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def process_input_text_query(input_string):\n",
    "    ob = NLP()\n",
    "    ob.input_query(input_string)\n",
    "    tensor = ob.processing()\n",
    "    print(tensor)\n",
    "    output_list = generic_process(tensor)\n",
    "    return output_list\n",
    "\n",
    "def process_input_image_query(path):\n",
    "    ob = ImageProcessing()\n",
    "    tensor = ob.image_process()\n",
    "    output_list = obj.image_movie(tensor)          # Contains string, image saved path\n",
    "    return output_list\n",
    "    \n",
    "def generic_process(tensor):\n",
    "    obj = Visualize()\n",
    "    count = tensor[0]\n",
    "    output = list()\n",
    "    output_string = ''\n",
    "    for i in range(1, tensor[0]+1):\n",
    "        output_string += '\\n'\n",
    "        if tensor[i]==\"role\":\n",
    "            output_string += obj.lead_role(tensor[i + count])\n",
    "            \n",
    "        elif tensor[i]==\"characters\":\n",
    "            output_string += obj.characters(tensor[i+count])\n",
    "        \n",
    "        elif tensor[i]==\"attitude\":\n",
    "            output_string += obj.character(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "        \n",
    "        elif tensor[i]==\"plot\":\n",
    "            output_string += obj.plot(tensor[i+count])\n",
    "        \n",
    "        elif tensor[i]==\"appearances\":\n",
    "            output_string += obj.appearances(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            \n",
    "        elif tensor[i]==\"year\":\n",
    "            output_string += obj.year(tensor[i+count])\n",
    "            \n",
    "        elif tensor[i]==\"songs\":\n",
    "            output_string += obj.songs(tensor[i+count])\n",
    "        \n",
    "        elif tensor[i]==\"emotion\":\n",
    "            try:\n",
    "                if (\"average\" in ob.temp):\n",
    "                    output_string += obj.average_emotion(tensor[i+count], 0)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"minor\" in ob.temp):\n",
    "                    output_string += obj.average_emotion(tensor[i+count], 1)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"major\" in ob.temp):\n",
    "                    output_string += obj.average_emotion(tensor[i+count], 2)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif(\"predict\" in ob.temp):\n",
    "                    output_string += obj.predict()\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "            except IndexError as e:\n",
    "                print(\"Not enough parameters\")\n",
    "                break\n",
    "        \n",
    "        elif tensor[i]==\"genre\":\n",
    "            output_string += obj.genre(tensor[i+count])\n",
    "            \n",
    "        elif tensor[i]==\"length\":\n",
    "            output_string += obj.length_of_movie(tensor[i+count])\n",
    "\n",
    "        elif tensor[i]==\"variation\":\n",
    "            output_string += obj.trends(True)\n",
    "\n",
    "        else:\n",
    "            print(\"Query does not contain enough parameters.\")\n",
    "        \n",
    "        output.append(output_string)\n",
    "        output_string = \"\"\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 'role', 'characters', 'attitude', 'appearances', 'plot', 'year', 'songs', 'genre', 'length', 'shamitabh', 'shamitabh', 'pandey', 'shamitabh', 'pandey', 'shamitabh', 'shamitabh', 'shamitabh', 'black_mail', '3_idiots', 'shamitabh']\n",
      "\n",
      "The lead role is:pandey\n",
      "The type of role played is: assistant\n",
      "\n",
      "The characters in the movies shamitabh include:\n",
      "        name  character\n",
      "1141  pandey  assistant\n",
      "\n",
      "The role is: pandey\n",
      "The type of role played is: assistant\n",
      "\n",
      "The role is:pandey\n",
      "The number of appearances are: 11\n",
      "The average centrality is: 7.636363636\n",
      "The total centrality is: 84.0\n",
      "\n",
      "The plot of the film goes like: 673     Danish  born mute in rural Igatpuri  loves films. He acts out scenes before his class  amazing his peers and teacher  and spends all his time in the local Paradise theatre. He even tries to board a Mumbai bus to go become a film star but is pulled off by his mother 's friends. When he grew up  Danish brings pakodas to the local video-store owner and watches films every day. His mother feigns illness and keeps him from going to Mumbai but when she dies  Danish leaves for Mumbai. Danish gets into Film City past Film guards and finds shelter in an actor 's vanity van  hiding under the sofa. Travelling around in the empty van  Danish desperately tries to meet directors but can not. He meets assistant director Akshara Pandey who is impressed by his talent. She shows his video  shot on her phone  to a director but he rejects casting a mute hero. Akshara 's father  a doctor  treats Danish after he gets into a fight with security guards. On his recommendation  Danish and Akshara arrive at Finland to meet his friend who shows Danish new `` Live Voice Transfer Technology   that uses embedded micro-recorders and ear-pieces and enables mute people to communicate via a `` borrowed  voice. Akshara and Danish return to Mumbai with the equipment and find Amitabh Sinha  a failed actor and drunkard. Although he was rejected because of his deep baritone  the duo are actually impressed with the same baritone and ask him to lend his voice to Danish  he accepts  and signs an agreement not to disclose himself as Danish 's voice. Danish first project becomes a major success and numerous film offers come for Danish  now named `` Shamitabh . Amitabh  who is officially Danish 's valet  also wants a role in accepting or rejecting scripts. He tells Danish his voice is as big -- if not bigger -- a star than Danish 's talent. The friction between Danish grows. Amitabh gets fever and Danish makes him take an injection. In retaliation  Amitabh makes Danish accepts singing a song in his new film. Amitabh sings the song `` Piddly   but is horrified by Amitabh picturisation of toilets across snowy peaks  suggested by Danish to tease him. Danish arrives at London to deliver a speech which Amitabh voices for him  but Danish treats him like a servant. Amitabh later becomes inebriated and attacks a police officer  leading to Amitabh arrest  but Danish bails Amitabh out. When the duo return to Mumbai  journalists ask Danish if Amitabh is apologetic about the incident. Amitabh mischievously makes Amitabh reply in negative  much to Danish 's fury. The duo parts ways  Danish plays a mute person in Amitabh next film  while Amitabh dubs for another actor in a different film. Both films fail. Meanwhile  Akshara  who had gone to Sikkim to write a script for Danish  returns but berates Danish when Amitabh refuses to apologise to Amitabh. Akshara forces Amitabh and Danish to reconcile. A media reporter  having discovered the secret that Danish was born mute  threatens to expose the duo but decide to tell the truth and surprise the world. Danish and Amitabh accept to work in Akshara 's debut film  and Danish tells Akshara that Akshara loves Akshara. While Danish and Amitabh are on the way to Akshara 's film ceremony  a car accident occurs  Danish is killed while Amitabh 's larynx is damaged  making Akshara mute. Some time later  Amitabh paces around Danish 's grave with Akshara 's script  imagining that Danish is still alive and practicing Akshara lines for the film\n",
      "Name: plot, dtype: object\n",
      "\n",
      "The movie shamitabh released in the year2015\n",
      "\n",
      "The movie black_mail is not found in the database. Try again with another value.\n",
      "\n",
      "\n",
      "GENRE:\n",
      "The movie 3_idiots is a Drama genre film.\n",
      "\n",
      "The predicted length of movie shamitabh on the basis of Centrality and Mentions is about 2.33\n"
     ]
    }
   ],
   "source": [
    "result = process_input_text_query(\"Lead role in the movie shamitabh and What are the characters in the movie shamitabh and What is the attitude of character pandey in movie shamitabh and What are the appearances of character pandey in movie shamitabh and what is the plot of movie shamitabh and which year did the movie shamitabh release and how many songs are there in movie black_mail and what is the genre of the movie 3_idiots and what is the length of movie shamitabh\")\n",
    "for i in result:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 'role', 'year', 'shamitabh', 'shamitabh']\n",
      "\n",
      "The lead role is:pandey\n",
      "The type of role played is: assistant\n",
      "\n",
      "The movie shamitabh released in the year2015\n"
     ]
    }
   ],
   "source": [
    "result = process_input_text_query(\"what is lead role in movie shamitabh and what is release year of movie shamitabh\")\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
